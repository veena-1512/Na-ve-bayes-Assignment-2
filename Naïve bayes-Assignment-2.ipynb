{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26438fa4-524e-4612-adb2-b72c83a46ee0",
   "metadata": {},
   "source": [
    "Q1. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm commonly used in machine learning for text classification tasks. They differ primarily in the assumptions they make about the distribution of feature variables.\n",
    "\n",
    " Bernoulli Naive Bayes:\n",
    "\n",
    "Assumes that the features are binary-valued (e.g., presence or absence of a term in a document).\n",
    "Typically used for text classification tasks where the presence or absence of words in a document is the primary concern.\n",
    "It models the presence or absence of each term in the document as a binary variable.\n",
    "It is suitable when your feature vectors are binary (i.e., occurrence of a word or not in the document).\n",
    "\n",
    " Multinomial Naive Bayes:\n",
    "\n",
    "Assumes that the features represent counts or frequencies (e.g., term frequency in a document).\n",
    "Often used in text classification where the frequency of terms (words) is considered rather than just their presence.\n",
    "It models the occurrence counts of each term in the document.\n",
    "It is suitable when your feature vectors represent counts or frequencies, such as term frequency-inverse document frequency (TF-IDF) vectors commonly used in text classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb8294-0a3d-4e53-ba89-d219ee4f8c6a",
   "metadata": {},
   "source": [
    "Q2. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "Bernoulli Naive Bayes, like other Naive Bayes variants, is generally not explicitly designed to handle missing values. However, there are a few common strategies for dealing with missing values when using Bernoulli Naive Bayes:\n",
    "\n",
    "1. Imputation: One approach is to impute missing values with a placeholder value before applying the Bernoulli Naive Bayes algorithm. For binary features, missing values could be replaced with either 0 or 1, depending on the context and the nature of the missingness. However, this approach may introduce bias or noise into the data.\n",
    "\n",
    "2. Ignore Missing Values: Another approach is to simply ignore instances with missing values during training and classification. This means that any instance with missing values would not contribute to the probability estimation for any class. While straightforward, this approach may result in loss of valuable information, particularly if there are many instances with missing values.\n",
    "\n",
    "3. Advanced Imputation Techniques: More sophisticated imputation techniques could also be employed, such as mean imputation, mode imputation, or using machine learning-based imputation methods like k-nearest neighbors (KNN) or predictive mean matching. However, these methods may introduce additional complexity and computational overhead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e1baa-7944-45bf-aaad-bbc8dcd7bde0",
   "metadata": {},
   "source": [
    "Q3. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that assumes that continuous features follow a Gaussian (normal) distribution. It's particularly suitable for features that are real-valued.\n",
    "\n",
    "For multi-class classification, Gaussian Naive Bayes extends naturally by using the principle of maximum a posteriori (MAP) estimation to classify instances into multiple classes. It calculates the posterior probability of each class given the input features and selects the class with the highest posterior probability as the predicted class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f6f61-723d-4992-9c4a-4ba48bb5f1dd",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "    \n",
    "    Data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bfa78c-8ca4-4ec1-95f9-f48ad49f6d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "def download_spambase_dataset(url, save_path):\n",
    "    response = requests.get(url)\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "save_path = \"spambase.data\"\n",
    "\n",
    "download_spambase_dataset(url, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e17c44-f9f0-4ef5-8813-92263f043747",
   "metadata": {},
   "source": [
    "Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fe52cb-8708-4864-acc8-2c26c0679f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b3d8a3-0710-4392-b75e-0d25f6954711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml(name='spambase', version=1, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656b73c1-ab21-4419-ba1e-eb6df0841a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3fe9012-ca5c-4450-b048-1762fa16f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Mean Accuracy: 0.8839380364047911\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_scores = cross_val_score(bernoulli_nb, X, y, cv=10)\n",
    "print(\"Bernoulli Naive Bayes Mean Accuracy:\", np.mean(bernoulli_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941489c6-4457-4a9b-ad17-8dd6675b3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Mean Accuracy: 0.7863496180326323\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb = MultinomialNB()\n",
    "multinomial_scores = cross_val_score(multinomial_nb, X, y, cv=10)\n",
    "print(\"Multinomial Naive Bayes Mean Accuracy:\", np.mean(multinomial_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326bd65b-b936-4849-b473-0e2d2369b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Mean Accuracy: 0.6796321795718192\n"
     ]
    }
   ],
   "source": [
    "gaussian_nb = make_pipeline(KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'), GaussianNB())\n",
    "gaussian_scores = cross_val_score(gaussian_nb, X, y, cv=10)\n",
    "print(\"Gaussian Naive Bayes Mean Accuracy:\", np.mean(gaussian_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451d880-5b08-4bc9-9239-26c8144e04f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da6dcf8-392b-4561-97a9-c4607f7ea554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e3dbcf-3d5e-419c-b91e-ed58c8077f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml(name='spambase', version=1, as_frame=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.data\n",
    "y = data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4109ae-56dd-4006-8f82-93b96aacab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: nan\n",
      "Precision: nan\n",
      "Recall: nan\n",
      "F1 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 107, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 268, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['0', '1']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb = BernoulliNB()\n",
    "bernoulli_results = cross_validate(bernoulli_nb, X, y, cv=10, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(\"Accuracy:\", np.mean(bernoulli_results['test_accuracy']))\n",
    "print(\"Precision:\", np.mean(bernoulli_results['test_precision']))\n",
    "print(\"Recall:\", np.mean(bernoulli_results['test_recall']))\n",
    "print(\"F1 Score:\", np.mean(bernoulli_results['test_f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833417a4-b663-4938-837b-1dc615fc1f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9004de9-ad34-4444-8c6e-4c0de13381ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303bb67-d509-4d9c-a6b9-7a6dd6e8f19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14360e-9e9d-402c-868f-ed6556dfe45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
